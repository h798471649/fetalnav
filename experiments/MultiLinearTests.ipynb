{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import stack\n",
    "from fetalnav.models.spn_models import vgg11_sp, vgg13_sp\n",
    "\n",
    "model = vgg11_sp(num_classes=7, num_maps=512, batch_norm=True, in_channels=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPNetWSL(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d (1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (4): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (6): ReLU(inplace)\n",
       "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (8): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (10): ReLU(inplace)\n",
       "    (11): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (13): ReLU(inplace)\n",
       "    (14): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (15): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (17): ReLU(inplace)\n",
       "    (18): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (20): ReLU(inplace)\n",
       "    (21): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (22): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (27): ReLU(inplace)\n",
       "  )\n",
       "  (spatial_poolings): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (adconv): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "      (maps): ReLU()\n",
       "      (sp): SoftProposal([couple=True,factor=None])\n",
       "      (sum): SpatialSumOverMap\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (adconv): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "      (maps): ReLU()\n",
       "      (sp): SoftProposal([couple=True,factor=None])\n",
       "      (sum): SpatialSumOverMap\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (adconv): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "      (maps): ReLU()\n",
       "      (sp): SoftProposal([couple=True,factor=None])\n",
       "      (sum): SpatialSumOverMap\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (adconv): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "      (maps): ReLU()\n",
       "      (sp): SoftProposal([couple=True,factor=None])\n",
       "      (sum): SpatialSumOverMap\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (adconv): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "      (maps): ReLU()\n",
       "      (sp): SoftProposal([couple=True,factor=None])\n",
       "      (sum): SpatialSumOverMap\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (adconv): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "      (maps): ReLU()\n",
       "      (sp): SoftProposal([couple=True,factor=None])\n",
       "      (sum): SpatialSumOverMap\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (adconv): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "      (maps): ReLU()\n",
       "      (sp): SoftProposal([couple=True,factor=None])\n",
       "      (sum): SpatialSumOverMap\n",
       "    )\n",
       "  )\n",
       "  (classifiers): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=1)\n",
       "    (1): Linear(in_features=512, out_features=1)\n",
       "    (2): Linear(in_features=512, out_features=1)\n",
       "    (3): Linear(in_features=512, out_features=1)\n",
       "    (4): Linear(in_features=512, out_features=1)\n",
       "    (5): Linear(in_features=512, out_features=1)\n",
       "    (6): Linear(in_features=512, out_features=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.1057 -0.0844 -0.0116  0.1061 -0.1062  0.0735 -0.0811\n",
       " 0.0819 -0.0806  0.0044  0.1203 -0.0929  0.0458 -0.0578\n",
       " 0.1003 -0.0786 -0.0178  0.1076 -0.0700  0.0541 -0.0741\n",
       " 0.1177 -0.1038  0.0020  0.0961 -0.0768  0.0466 -0.0603\n",
       "[torch.cuda.FloatTensor of size 4x7 (GPU 0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelcuda = torch.nn.DataParallel(model).cuda()\n",
    "input_batch = torch.randn(4, 1, 112, 112)\n",
    "o = modelcuda(Variable(input_batch))\n",
    "print(o.shape)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2292 -0.1126  0.0753  0.0207 -0.0055  0.0044  0.0347\n",
       " 0.2315 -0.1079  0.0622  0.0321  0.0184 -0.0009  0.0171\n",
       " 0.2193 -0.1165  0.0771  0.0354  0.0232  0.0244  0.0029\n",
       " 0.2274 -0.0976  0.0724  0.0145  0.0048 -0.0054  0.0242\n",
       "[torch.cuda.FloatTensor of size 4x7 (GPU 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     1     0     0     0     0     0\n",
       "    0     1     1     1     1     0     0\n",
       "    0     0     1     0     0     0     0\n",
       "    0     0     0     1     0     0     0\n",
       "[torch.FloatTensor of size 4x7]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = 0.\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "trying to index 3 dimensions of a 2 dimensional tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-165d692619ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiLinearMultiLabelSoftMarginLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-165d692619ad>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mclass_input\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mclass_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultilabel_soft_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mIndexSelect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# else fall through and raise an error in Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, index)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_shared_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: trying to index 3 dimensions of a 2 dimensional tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "class MultiLinearMultiLabelSoftMarginLoss(nn.MultiLabelSoftMarginLoss):\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        out = 0.\n",
    "        for idx in range(input.size(1)):\n",
    "            class_input  = input[:, idx]\n",
    "            class_target = target[:, idx]\n",
    "            v = F.multilabel_soft_margin_loss(class_input, class_target, weight=self.weight)\n",
    "            out += v\n",
    "        return out\n",
    "\n",
    "t = torch.zeros(o.size(0), o.size(1))\n",
    "t[0,0] = t[0,1] = 1.\n",
    "t[1,1] = t[1,2] = 1.\n",
    "t[2,2] = t[1,3] = 1.\n",
    "t[3,3] = t[1,4] = 1.\n",
    "state = {}\n",
    "state['output']= o.data.cpu()\n",
    "state['target']= t\n",
    "\n",
    "\n",
    "loss = MultiLinearMultiLabelSoftMarginLoss()\n",
    "\n",
    "loss(Variable(state['output']), Variable(state['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 112, 112])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from scipy.misc import imresize\n",
    "from scipy.ndimage import label\n",
    "from spn.modules import SoftProposal\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def hook_spn(model):\n",
    "    if not (hasattr(model, 'sp_hook') and hasattr(model, 'fc_hook')):\n",
    "        model._training = model.training\n",
    "        model.train(False)\n",
    "        \n",
    "        def _pre_sp_hook(self, input, output):\n",
    "            print(self.name)\n",
    "            self.parent_modules[0].class_response_maps = output\n",
    "        def sp_hook(self, input, output):\n",
    "            print(self.name)\n",
    "            self.parent_modules[0].class_response_maps = output\n",
    "        def _fc_hook(self, input, output):\n",
    "            if hasattr(self.parent_modules[0], 'class_response_maps'):\n",
    "                self.parent_modules[0].class_response_maps = F.conv2d(self.parent_modules[0].class_response_maps, self.weight.unsqueeze(-1).unsqueeze(-1))\n",
    "            else:\n",
    "                raise RuntimeError('The SPN is broken, please recreate it.')\n",
    "                \n",
    "        sp_layers = []\n",
    "        fc_layers = []\n",
    "        for mod in model.modules():\n",
    "            if isinstance(mod, SoftProposal):\n",
    "                sp_layers.append(mod)\n",
    "            elif isinstance(mod, torch.nn.Linear):\n",
    "                fc_layers.append(mod)\n",
    "        \n",
    "        if not len(sp_layers) or not len(sp_layers):\n",
    "            raise RuntimeError('Invalid SPN model')\n",
    "        else:\n",
    "            for s in sp_layers:\n",
    "                s.parent_modules = [model]\n",
    "                model.sp_hook = s.register_forward_hook(_sp_hook)\n",
    "            for s in sp_layers:\n",
    "                s.parent_modules = [model]\n",
    "                model.fc_hook = s.register_forward_hook(_fc_hook)\n",
    "    return model\n",
    "\n",
    "def generate_outputs(model, in_var):\n",
    "\n",
    "    from spn import hook_spn\n",
    "    from torch.nn import functional as F\n",
    "\n",
    "    if in_var.ndimension() == 3:\n",
    "        input = in_var.unsqueeze(0)\n",
    "    assert in_var.size(0) == 1, 'Batch processing is currently not supported'\n",
    "    # enable spn inference mode\n",
    "    model = hook_spn(model)\n",
    "    # predict scores\n",
    "    scores = torch.nn.Softmax(dim=1)(model(in_var)).data.cpu().squeeze()\n",
    "    # instantiate maps\n",
    "    maps = F.upsample(model.class_response_maps, size=(in_var.size(2), in_var.size(3)), mode='bilinear').data\n",
    "    return scores.numpy(), maps\n",
    "\n",
    "input_batch = torch.randn(1, 1, 112, 112)\n",
    "a = generate_outputs(model, Variable(input_batch.cuda()))\n",
    "\n",
    "a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x7fc50160c678>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Linear(10,2)\n",
    "a.named_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
